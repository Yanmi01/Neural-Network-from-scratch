# Neural Network from Scratch

This repository contains the implementation of backpropagation and a neural network from scratch using Python.

## Introduction
In this project, I built a neural network from scratch as well as implemented backprop from scratch without any external library. This repository follows Andrej Karpathy's "The spelled-out intro to neural networks and backpropagation: building micrograd" tutorial on youtube. 
There's the rough colab notebook which follows him stepwisely and builds everything explaining each concept without skipping ang. you can run the notebook and see how it all happened and what caused each changes at each steps.
There's also a cleaner jupyter notebook that shows a straightfoward path to the implementations. 
Finally, there's the .py files that cleans the code up and breaks them up into cleaner subsidiaries. 

## Installation
To use this code, you need to have Python installed on your system. Clone this repository to your local machine using the following command:

```
git clone https://github.com/your-username/Neural-Network-from-scratch.git
```

## Contributing
Contributions are welcome! If you have any suggestions or improvements, feel free to open an issue or submit a pull request.